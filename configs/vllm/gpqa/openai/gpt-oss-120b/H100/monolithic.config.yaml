compilation-config: '{"cudagraph_mode":"PIECEWISE"}'
async-scheduling: true
max-num-batched-tokens: 8192
max-model-len: 51200
# enable-expert-parallel: true  # vLLM recipes recommend TP
dtype: auto
trust-remote-code: true
reasoning-parser: openai_gptoss
api-server-count: 8
