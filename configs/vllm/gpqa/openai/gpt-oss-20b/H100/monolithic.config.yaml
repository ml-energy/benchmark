compilation-config: '{"cudagraph_mode":"PIECEWISE"}'
async-scheduling: true
max-num-batched-tokens: 8192
max-model-len: 20480
dtype: auto
reasoning-parser: openai_gptoss
